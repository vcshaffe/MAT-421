{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJlFTtV+EE9+bQvFvJW/qb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vcshaffe/MAT-421/blob/main/ModuleE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2 Continuity and Differentiation\n",
        "\n",
        "Def 3.2.1 (Limits of a function): limit of f(x) as x approaches a value a, or lim x->a f(x) = L\n",
        "\n",
        "Def 3.2.2 (Continuous function): Real valued function f is continuous at a if lim x->a f(x) = f(a).\n",
        "\n",
        "**3.2.2 Derivatives**\n",
        "\n",
        "Def 3.2.6 (Derivative) - f'(x0) = lim h->0 (f(x0 + h) - f(x0)) / h\n",
        "\n",
        "Thm 3.2.9 (Rolle) - Let f:[a,b] -> R be a cts function and its derivative exists on (a,b). If f(a) = f(b), then there is a < c < b such that f'(c) = 0.\n",
        "\n",
        "Thm 3.2.10 (Mean Value) - Let f:[a,b] -> R be a cts function and its derivative exists on (a,b). Then there is a < c < b such that f(b) = f(a) + (b - a) * f'(c).\n",
        "\n",
        "Thm 3.2.15 (Chain Rule) - Let f : D1 -> R^m, where D1 ⊆ R^d, and let g: D2 -> R^p, where D2 ⊆ R^m. Assume f is continuously diff'ble at x0, and interior point of D1, and that g is continuously diff'ble at f(x0), an interior point of D2. Then, Jgof(x0) = Jg(f(x0))Jf(x0) as a product of matrices.\n",
        "\n",
        "Def 3.2.16 (Directional Derivatives) - Let f: D-> R where D ⊆ R^d, let x0 ∈ D be an interior point of D and let v ∈ R^d be a unit vector. The directional derivative of f at x0 in the direction of v is ∂f(x0)/∂v = lim h->0 (f(x0 + hv) - f(x0))/h, provided the limit exists.\n",
        "\n",
        "Thm 3.2.21 (Taylor's Thm) - Let f: D -> R where D ⊆ R. Suppose f has a m times continuous derivative on [a,b]. Then, f(b) = f(a) + (b - a)*f'(a) + 1/2(b - a)^2 * f''(a) + ... + (((b-a)^(m-1)) / (m-1)!) * f^(m-1) * (a) + Rm  \n",
        "--f derivatives\n",
        "\n",
        "Thm 3.2.22 (Multivariate Mean Value) - Let f: D-> R where D ⊆ R^d. Let x0 ∈ D and δ > 0 be such that Bδ(x0) ⊆ D. If f is continuously diff'ble on Bδ(x0), then for any x ∈ Bδ(x0), f(x) = f(x0) + ∇f(x0 + ξp)^T * p.\n",
        "for some ξ ∈ (0,1) , and p=x - x0.\n",
        "\n",
        "Thm 3.2.23 (Multivariate Taylor) - Let f: D -> R where D ⊆ R^d. Let x0 ∈ D and δ>0 be such that Bδ(x0)⊆ D. If f is three times continuously diff'ble on Bδ(x0), then for any x ∈ Bδ(x0)\n",
        "\n",
        "f(x) = f(x0) + ∇f(x0)^T * p + 1/2p^T * Hf(x0) * p + O(|p||^3), where p = x - x0."
      ],
      "metadata": {
        "id": "r2E6T7RWtnsU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.3 Unconstrained Optimization\n",
        "\n",
        "Def 3.3.1 (Global Minimizer) - Let f: R^d -> R. The point x^* ∈ R^d is a global minimizer of f over R^d if f(x) ≥ f(x^*), ∀x ∈ R^d.\n",
        "\n",
        "Def 3.3.2 (Local Minimizer) - Let f: R^d -> R. The point x^* ∈ R^d is a local minimizer of f over R^d if there is მ > 0 such that\n",
        "f(x) ≥ f(x^*), ∀x ∈ Bმ(x^*) \\ {x^*}.\n",
        "\n",
        "Def 3.3.3 (Descent Direction) - Let f:R^d -> R. A vector v is a descent direction for f at x0 if there is α^* > 0 such that \n",
        "f(x0 + αv) < f(x0), ∀α ∈ (0,α^∗).\n",
        "\n",
        "Lemma 3.3.4 (Descent Direction and Directional Derivative) - Let f : R^d → R be continuously diff'ble at x0. A vector v is a descent direction for f at x0 if\n",
        "\n",
        "(∂f(x0)/∂v) =∇f(x0)^T * v < 0, \n",
        "\n",
        "if the directional derivative of f at x0 in the direction v is negative.\n",
        "\n",
        "Thm 3.3.6 (First-Order Necessary Condition) - Let f: R^d -> R be continuously diff'ble on R^d. If x0 is a local minimizer, then ∇f(x0) = 0.\n",
        "\n",
        "Def 3.3.7 (Positive semi-definite (PSD)) - A square symmetric d x d matrix H is positive semi-definite (PSD) if x^T Hx ≥ 0 for any x ∈ R^d.\n",
        "\n",
        "Thm 3.3.8 (Second-Order Necessary Condition) - Let f: R^d -> R be continuously diff'ble on R^d. If x0 is a local minimizer, then Hf(x0) is PSD.\n",
        "\n",
        "Thm 3.3.10 (Second-Order Sufficient Condition) - Let f: R^d -> R be twice continuously diff'ble on R^d. If ∇f(x0) = 0 and Hf(x0) is postiive definite, then x0 is a strict local minimizer.\n",
        "\n",
        "**Convex Sets**\n",
        "\n",
        "Def 3.3.11 (Convex Set) - A set D ⊆ R&d is convex if for all x,y ∈ D and all α ∈ [0,1],\n",
        "\n",
        "(1-α)x + αy ∈ D\n",
        "\n",
        "Def 3.3.13 (Convex Function) - A function f: R^d -> R is convex if, for all x,y ∈ R^d and all α ∈ [0,1],\n",
        "\n",
        "f((1-α)x + αy) ≤ (1− α)f(x) + αf(y).\n",
        "\n",
        "Lemma 3.3.14 (Affine Functions are Convex) - Let w ∈ R^d and b ∈ R. The function f(x)=w^T * x + b is convex.\n",
        "\n",
        "Lemma 3.3.15 (First-Order Convexity Condition) - Let f: R^d → R be continuously diff'ble. Then f is convex if and only if for all x,y ∈ R^d\n",
        "\n",
        "f(y) ≥ f(x) + ∇f(x)^T * (y− x).\n",
        "\n",
        "Lemma 3.3.16 (Second-Order Convexivity Condition) - Let f: R^d → R be twice continuously diff'ble. Then f is convex if and only if, for all x ∈ R^d,Hf(x) is PSD.\n",
        "\n",
        "Thm 3.3.18 - Let f: R^d → R be a continuously diff'ble, convex function. If ∇f(x0) = 0, then x0 is a global minimizer.\n",
        "\n",
        "Thm 3.3.19 (Global Minimizers of Convex Functions) - Let f: R^d → R be a convex function. Then any local minimizer of f is also a global minimizer.\n",
        "\n",
        "**Gradient Descent**\n",
        "\n",
        "Lemma 3.3.22 (Steepest Descent) - Let f: R^d → R be continuously diff'ble at x0. For any unit vector v ∈ R^d, ((∂f(x0)) / (∂v)) ≥ ((∂f(x0)) / (∂v^*)),\n",
        "\n",
        "where v^* = - (∇f(x0))/(||∇f(x0)||)."
      ],
      "metadata": {
        "id": "P7oAJgrTyTng"
      }
    }
  ]
}